{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook we will only clean and prepare the data for an analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines are used to ignore error messages that occur using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use pandas to load our CSV file so that we can work with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('lyrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will look at the different genres that exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pop', 'Hip-Hop', 'Not Available', 'Other', 'Rock', 'Metal',\n",
       "       'Country', 'Jazz', 'Electronic', 'Folk', 'R&B', 'Indie'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.genre.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to use _Not Available_ or _Other_, so therefore we are deleting these two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.genre != 'Not Available') & (df.genre != 'Other')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to remove the rows where the years are not reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2009, 2007, 2013, 2010, 2012, 2006, 2016, 2011, 2015, 2008, 2014,\n",
       "       1998, 2002, 1995, 2004, 1972, 2005, 1978, 1970, 1981, 1994, 1997,\n",
       "       2003, 1983, 1987, 1993, 1982, 1986, 1992, 1984, 1977, 1989, 1979,\n",
       "       1996, 2001, 1999, 1990, 1974, 1975, 1973, 1991, 1985, 1971, 2000,\n",
       "       1980, 1976,  702, 1988,  112, 2038, 1968,   67], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df.year.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    if year < 1900:\n",
    "        df = df[df.year != year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want lyrics from _2038_ either, so we'll delete these as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.year != 2038]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to delete all rows that have _NaN_ as lyrics as we are analyzing the lyrics as we are only interested in lyrics to build our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.lyrics.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have cleaned the data. Now we will make it ready to be analyzed.\n",
    "<br>\n",
    "We are going to do the following:<br>\n",
    "Lowercasing: Tomato → tomato<br>\n",
    "Normalization: normalisation → normalization<br>\n",
    "Stemming or lemmatization: dogs -> dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove all special characters:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyrics'] = [x.strip().replace('\\n', ' ')\n",
    "                     .replace('!', '')\n",
    "                     .replace('?', '')\n",
    "                     .replace(',', '')\n",
    "                     .replace('.', '')\n",
    "                     .replace('\\t', '')\n",
    "                      for x in df['lyrics']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will see how our lyrics look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh baby how you doing You know I'm gonna cut right to the chase Some women were made but me myself I like to think that I was created for a special purpose You know what's more special than you You feel me It's on baby let's get lost You don't need to call into work 'cause you're the boss For real want you to show me how you feel I consider myself lucky that's a big deal Why Well you got the key to my heart But you ain't gonna need it I'd rather you open up my body And show me secrets you didn't know was inside No need for me to lie It's too big it's too wide It's too strong it won't fit It's too much it's too tough He talk like this 'cause he can back it up He got a big ego such a huge ego I love his big ego it's too much He walk like this 'cause he can back it up Usually I'm humble right now I don't choose You can leave with me or you could have the blues Some call it arrogant I call it confident You decide when you find on what I'm working with Damn I know I'm killing you with them legs Better yet them thighs Matter a fact it's my smile or maybe my eyes Boy you a site to see kind of something like me It's too big it's too wide It's too strong it won't fit It's too much it's too tough I talk like this 'cause I can back it up I got a big ego such a huge ego But he love my big ego it's too much I walk like this 'cause I can back it up I I walk like this 'cause I can back it up I I talk like this 'cause I can back it up I I can back it up I can back it up I walk like this 'cause I can back it up It's too big it's too wide It's too strong it won't fit It's too much it's too tough He talk like this 'cause he can back it up He got a big ego such a huge ego such a huge ego I love his big ego it's too much He walk like this 'cause he can back it up Ego so big you must admit I got every reason to feel like I'm that bitch Ego so strong if you ain't know I don't need no beat I can sing it with piano\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lyrics'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want to use English lyrics as well, so we will delete all rows that are in non English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237421, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langdetect\n",
    "from langdetect import detect\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        if detect(row['lyrics']) != 'en':\n",
    "            df.drop(index, inplace=True)\n",
    "    except:\n",
    "        df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216614, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lyrics look good. Now we need to split the string into an array of elements so that our function can train (it only accepts tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyrics'] = df['lyrics'].apply(lambda x: [item for item in x.split(' ') if item.lower() not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemSentence(sentence):\n",
    "    stem_sentence=[]\n",
    "    for word in sentence:\n",
    "        stem_sentence.append(porter.stem(word.lower()))\n",
    "    return stem_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['lyrics'] = [stemSentence(x) for x in df['lyrics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./cleaned.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
